- **Broker**：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群；
- **Topic**：一类消息，例如page view日志、click日志等都可以以topic的形式存在，Kafka集群能够同时负责多个topic的分发；
- **Partition**：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队；
- **Segment**：每个partition又由多个segment file组成；
- **offset**：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset，用于partition唯一标识一条消息；
- **message**：这个算是kafka文件中最小的存储单位，即是 a commit log。

消息是持久化至`磁盘`!

Screen Shot 2021-06-29 at 12.56.01 PM.png<img width="669" alt="Screen Shot 2021-06-29 at 12 56 01 PM" src="https://user-images.githubusercontent.com/17567449/123739575-71949d80-d8d9-11eb-9087-bcd34891116c.png">


数据存储topic.png![数据存储topic](https://user-images.githubusercontent.com/17567449/123732035-e19c2700-d8cb-11eb-8142-75d6f18cc1b2.png)

segment
segment.png<img width="276" alt="segment" src="https://user-images.githubusercontent.com/17567449/123732064-ed87e900-d8cb-11eb-8ab1-e6c9196dab30.png">
segment的索引文件中存储着大量的元数据，数据文件中存储着大量消息，索引文件中的元数据指向对应数据文件中的message的物理偏移地址。以索引文件中的3，497为例，在数据文件中表示第3个message（在全局partition表示第368772个message），以及该消息的物理偏移地址为497。

注：Partition中的每条message由offset来表示它在这个partition中的偏移量，这个offset并不是该Message在partition中实际存储位置，而是逻辑上的一个值（如上面的3），但它却唯一确定了partition中的一条Message（可以认为offset是partition中Message的id）。



### 磁盘存储

- 顺序写盘的速度不仅比随机写盘的速度快，而且也比随机写内存的速度快。

![截屏2021-07-26 22.15.50](/Users/zz/Library/Application Support/typora-user-images/截屏2021-07-26 22.15.50.png)

- Kafka 在设计时采用了文件追加的方式来写入消息，即只能在日志文件的尾部追加新的消

  息，井且也不允许修改己写入的消息，这种方式属于典型的顺序写盘的操作



#### 页缓存

- 页缓存是操作系统实现的一种主要的磁盘缓存，以此用来减少对磁盘 I/O 的操作。具体来说，就是把磁盘中的数据缓存到内存中，把对磁盘的访问变成对内存的访问。
- Kafka 中大量使用了页 缓存 ，这是 Kafka 实现高 吞 吐的重要因素之 一。 虽然消息都是先被 写入页缓存，然后由操作系统负责具体的刷盘任务的



#### 零拷贝

考虑这样一种常用的情形 : 你需要将静态内容(类似图片、文件)展示给用户 。 这个情形就意味着需要先将静态内容 从磁盘中复制出来放到一个内存 buf中，然后将这个 buf通过套接字( Socket)传输给用户，进 而用户获得静态内容 。这看起来再正常不过了，但实际上这是很低效的流程 ，我们把上面的这 种情形抽象成下面的过程 :

```
read(file, tmp buf, len); 
write(socket, tmp buf, len);
```

首先调用 read()将静态内容(这里假设为文件 A)读取到 tmp buf，然后调用 write()将tmp_buf 写入 Socket，如 图 5-23 所示 。

在这个过程中， 文件 A 经历了 4 次复 制的过程:

1. 调用 read()时，文件 A 中的内容被复制到了 内核模式下的 ReadBuffer中。 
2.  CPU 控制将内核模式数据复制到用户模式下 。
3. 调用 writ巳()时，将用户模式下的 内容复制到内核模式下的 Socket Buffer 中 。
4. 将内核模式下的 SocketBuffer的数据复制到网卡设备中传迭。

![截屏2021-07-30 10.41.22](/Users/zz/Library/Application Support/typora-user-images/截屏2021-07-30 10.41.22.png)

从上面的过程可以看出，数据平白无故地从内核模式到用户模式“走了一圈”，浪费了 2 次复制过程:第一次是从内核模式复制到用户模式;第二次是从用户模式再复制回 内核模式， 即上面 4 次过程中的第 2 步和第 3 步。而且在上面的过程中，内核和用户模式的上下文的切换 也是 4 次。

如果采用了零拷贝技术，那么应用程序可以直接请求内核把磁盘中的数据传输给 Socket, 如图 5-24所示。

![截屏2021-07-30 10.42.44](/Users/zz/Library/Application Support/typora-user-images/截屏2021-07-30 10.42.44.png)

零拷贝技术通过 **DMA (Direct Memory Access)**技术将文件内容复制到内核模式下的 Read Buffer 中。不过没有数据被复制到 Socket Buffer，相反只有包含数据的位置和长度的信息的文件描述符被加到 Socket Buffer 中。 DMA 引擎直接将数据从内核模式中传递到网卡设备(协议 引 擎)。这里数据只经历了 2 次复制就从磁盘中传送出去了 ， 并且上下文切换也变成了 2 次。 零拷贝是针对内核模式而言的 ，数据在内核模式下实现了零拷贝 。



### 总结

Kafka高效文件存储设计特点：

- Kafka把topic中一个parition大文件分成多个小文件段，通过多个小文件段，就容易定期清除或删除已经消费完文件，减少磁盘占用。
- 通过索引信息可以快速定位message和确定response的最大大小。
- 通过index元数据全部映射到memory，可以避免segment file的IO磁盘操作。
- 通过索引文件稀疏存储，可以大幅降低index文件元数据占用空间大小。



refer:

 https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html

https://matt33.com/2016/03/08/kafka-store/



### 为什么kafka快？

1. 顺序读写
   - 充分利用磁盘特性，这是基础
2. 零拷贝
   - 零拷贝并不是不需要拷贝，而是减少不必要的拷贝次数
   - 数据直接在内核完成输入和输出，不需要拷贝到用户空间再写出去。
     kafka数据写入磁盘前，数据先写到进程的内存空间。
   - Customer从broker读取数据，采用sendfile，将磁盘文件读到OS内核缓冲区后，直接转到socket buffer进行网络发送。
3. mmap文件映射
   - Producer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入



#### mmap 和 sendfile总结

1. 都是Linux内核提供、实现零拷贝的API；
2. sendfile 是将读到内核空间的数据，转到socket buffer，进行网络发送；
3. mmap将磁盘文件映射到内存，支持读和写，对内存的操作会反映在磁盘文件上。
RocketMQ 在消费消息时，使用了 mmap。kafka 使用了 sendFile。

refer：
https://zhuanlan.zhihu.com/p/78335525
https://xie.infoq.cn/article/c06fea629926e2b6a8073e2f0

